[TTS流式服务](https://aistudio.baidu.com/projectdetail/5002407?channelType=0&channel=0)
[ASR流式服务](https://aistudio.baidu.com/projectdetail/4057599?channelType=0&channel=0)
[PaddleSpeech服务](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_server)
[PaddleSpeech Server RESTful API](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/README_cn.md)
# TTS流式服务

## 服务配置文件
无论是 http 协议还是 websocket 协议，启动服务都需要有服务配置 yaml 文件（tts_online_application.yaml）。

若想启动 http 协议的服务，将 `protocol` 设置为 `http` ；若想启动 websocket 协议的服务，将 `protocol` 设置为 `websocket`，配置文件内容如下：
``` YAML
host: 0.0.0.0
port: 8092

protocol: 'http'
engine_list: ['tts_online-onnx']

################### speech task: tts; engine_type: online #######################
tts_online: 
    # am (acoustic model) choices=['fastspeech2_csmsc', 'fastspeech2_cnndecoder_csmsc']      
    am: 'fastspeech2_csmsc'   
    am_config: 
    am_ckpt: 
    am_stat: 
    phones_dict: 
    tones_dict: 
    speaker_dict: 

    # voc (vocoder) choices=['mb_melgan_csmsc, hifigan_csmsc']
    voc: 'mb_melgan_csmsc'
    voc_config: 
    voc_ckpt: 
    voc_stat: 

    # others
    lang: 'zh'
    device: 'cpu' # set 'gpu:id' or 'cpu'
    am_block: 72
    am_pad: 12
    voc_block: 36
    voc_pad: 14
    

################### speech task: tts; engine_type: online-onnx #######################
tts_online-onnx: 
    # am (acoustic model) choices=['fastspeech2_csmsc_onnx', 'fastspeech2_cnndecoder_csmsc_onnx']      
    am: 'fastspeech2_cnndecoder_csmsc_onnx' 
    # am_ckpt is a list, if am is fastspeech2_cnndecoder_csmsc_onnx, am_ckpt = [encoder model, decoder model, postnet model];
    # if am is fastspeech2_csmsc_onnx, am_ckpt = [ckpt model];
    am_ckpt:          # list
    am_stat: 
    phones_dict: 
    tones_dict: 
    speaker_dict: 
    spk_id: 0
    am_sample_rate: 24000
    am_sess_conf:
        device: "cpu" # set 'gpu:id' or 'cpu'
        use_trt: False
        cpu_threads: 4

    # voc (vocoder) choices=['mb_melgan_csmsc_onnx, hifigan_csmsc_onnx']
    voc: 'hifigan_csmsc_onnx'
    voc_ckpt: 
    voc_sample_rate: 24000
    voc_sess_conf:
        device: "cpu" # set 'gpu:id' or 'cpu'
        use_trt: False
        cpu_threads: 4

    # others
    lang: 'zh'
    am_block: 72
    am_pad: 12
    voc_block: 36
    voc_pad: 14
    voc_upsample: 300
```

## 启动流式服务

``` Bash
paddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml
```

## 客户端接口定义

- **访问 http 流式 TTS 服务**  
    url: http://127.0.0.1:8092/paddlespeech/tts/stareaming  
    请求方式：POST  
    请求示例如下，该示例包含所有字段（目前流式 TTS 服务只使用到 text 字段，其他字段暂不生效）：

```
{
    "text": "您好，欢迎使用百度飞桨语音合成服务。",
    "spk_id": 0,
    "speed": 1.0,
    "volume": 1.0,
    "sample_rate": 0,
    "save_path": "./output.wav",
}
```

- **命令行**

``` Bash
paddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol
http --input "您好，欢迎使用百度飞桨语音合成服务。" --output output.wav
```

- **Python API**

``` python
from paddlespeech.server.bin.paddlespeech_client import TTSOnlineClientExecutor
import json

executor = TTSOnlineClientExecutor()
executor(
    input="您好，欢迎使用百度飞桨语音合成服务。",
    server_ip="127.0.0.1",
    port=8092,
    protocol="http",
    spk_id=0,
    output="./output.wav",
    play=False)
```

- **访问 websocket 流式 TTS 服务**  
    url: ws://127.0.0.1:8092/paddlespeech/tts/stareaming  
    

1. 首先建立 websocket 连接，建立连接后发送**开始请求**，请求示例如下：

```
{
    "task": "tts",
    "signal": "start"
}
```

成功响应开始请求的示例如下，其中 status 为 0 表示可以开始发送请求，signal 表示 server 是否准备好， session 为 40 位的随机字符串，用来表示此次连接的编号。

```
{
    "status": 0, 
    "signal": "server ready",
    "session": "UloVFXg3xjb2nIP6xH58Ms8G98vnA1thHL6snKOy"
}
```

2. server 端返回成功开始的响应后，client 端向服务端发送**流式语音合成请求**，请求示例如下。其中 text 字段表示待合成文本经过 base64 编码后的 string，下述 string 对应的文本为：您好，欢迎使用百度飞桨语音合成服务。

注意：流式 http request 直接传文本，websocket 传 base64 的 string，具体原因会在 FAQ 部分解释。

```
{
    "text": "5oKo5aW977yM5qyi6L+O5L2/55So55m+5bqm6aOe5qGo6K+t6Z+z5ZCI5oiQ5pyN5Yqh44CC",
}
```

成功响应示例如下，其中 status 字段表示音频片段是否为最后一段，status 为 2 表示该音频片段为最后一片段，status 为 1 表示该音频片段不是最后一片段；audio 字段表示音频片段经过 base64 编码后的 string。

```
{
    "status": 1,
    "audio": "LTI1OTIuNjI1OTUwMzQsOTk2OS41NDk4...",
    "session": "UloVFXg3xjb2nIP6xH58Ms8G98vnA1thHL6snKOy"
}
```

3. client 端收到 server 返回的 status 为 2 的最后一个音频片段的响应后，发送**结束连接的请求**，请求示例如下，其中 session 表示此次连接的编号。

```
{
    "task": "tts",
    "signal": "end",
    "session": "UloVFXg3xjb2nIP6xH58Ms8G98vnA1thHL6snKOy",
}
```

成功响应示例如下：

```
{
    "status": 0, 
    "signal": "connection will be closed",
    "session": "UloVFXg3xjb2nIP6xH58Ms8G98vnA1thHL6snKOy"
}
```

- **命令行**

``` Bash
paddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol websocket --input "您好，欢迎使用百度飞桨语音合成服务。" --output output.wav
```

- **Python API**

```python
from paddlespeech.server.bin.paddlespeech_client import TTSOnlineClientExecutor
import json

executor = TTSOnlineClientExecutor()
executor(
    input="您好，欢迎使用百度飞桨语音合成服务。",
    server_ip="127.0.0.1",
    port=8092,
    protocol="websocket",
    spk_id=0,
    output="./output.wav",
    play=False)
```

# ASR流式服务

## 服务配置文件

``` YAML
host: 0.0.0.0
port: 8090
protocol: 'websocket'
engine_list: ['asr_online']

asr_python:
    model: 'conformer_wenetspeech'
    lang: 'zh'
    sample_rate: 16000
    cfg_path: # [optional]
    ckpt_path: # [optional]
    decode_method: 'attention_rescoring'
    force_yes: True
    device:  # set 'gpu:id' or 'cpu'
protocol: 'websocket'
engine_list: ['asr_online']

asr_online:
    model_type: 'conformer_online_wenetspeech'
    am_model:            # the pdmodel file of am static model [optional]
    am_params:           # the pdiparams file of am static model [optional]
    lang: 'zh'
    sample_rate: 16000
    cfg_path: 
    decode_method: 
    force_yes: True
    device: 'cpu'        # cpu or gpu:id
    decode_method: "attention_rescoring"
    am_predictor_conf:
        device:          # set 'gpu:id' or 'cpu'
        switch_ir_optim: True
        glog_info: False # True -> print glog
        summary: True    # False -> do not show predictor config

    chunk_buffer_conf:
        window_n: 7      # frame
        shift_n: 4       # frame
        window_ms: 25    # ms
        shift_ms: 10     # ms
        sample_rate: 16000
        sample_width: 2
```

## 启动流式服务

``` Bash
paddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml
```

## 客户端接口定义

- **Python API**

``` python
from paddlespeech.server.bin.paddlespeech_client import ASROnlineClientExecutor

asrclient_executor = ASROnlineClientExecutor()
res = asrclient_executor(
    input="./zh.wav",
    server_ip="127.0.0.1",
    port=8090,
    sample_rate=16000,
    lang="zh_cn",
    audio_format="wav")
print(res)
```

- **命令行**

``` Bash
paddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input ./zh.wav
```